# configuration file for the unconditional training

# 1. Image processing
processing:
  # dataset name
  dataset: "data/images/breast10p" # name of the dataset or directory in repo
  # image size or resolution to resize
  resolution: 64
  interpolation: "BILINEAR"
  # normalisation
  normalisation_value: 4095.0
  # batch size for dataloader
  batch_size: 32
  # number of workers for dataloader
  num_workers: 8 # 0 means no extra processes are used (run in main process)

# 2. Model
model:
  in_channels: 1 # The number of channels in the input image, RGB -> 3
  out_channels: 1 # The number of channels in the output image, RGB -> 3
  layers_per_block: 2 # How many ResNet layers to use in each Unet block
  block_out_channels: !!python/tuple # The output channels for each block # More channels -> more parameters # The length of this tuple is the number of blocks
  - 128
  - 128
  - 256
  - 256
  - 512
  - 512  
  down_block_types: !!python/tuple # Describes the type of block to use for downsampling
  - "DownBlock2D"  # a regular ResNet downsampling block
  - "DownBlock2D"
  - "DownBlock2D"
  - "DownBlock2D"
  - "AttnDownBlock2D"  # a ResNet downsampling block with spatial self-attention
  - "DownBlock2D" # originaly a attention block, changed to a regular block
  up_block_types: !!python/tuple # Describes the type of block to use for upsampling
  - "UpBlock2D"
  - "AttnUpBlock2D"  # a ResNet upsampling block with spatial self-attention
  - "UpBlock2D"
  - "UpBlock2D"  # a regular ResNet upsampling block
  - "UpBlock2D"
  - "UpBlock2D"

# 3. Training
training:
  num_epochs: 50 # Number of epochs to train for
  gradient_accumulation:
    steps: 1 # Number of gradient accumulation steps
  mixed_precision:
    type: 'no'
  gradient_clip:
    max_norm: 1.0 # Maximum norm for gradient clipping
  optimizer:
    learning_rate: 1.0e-4 # Learning rate for the optimizer
    beta_1: 0.95 # Beta 1 for the AdamW optimizer
    beta_2: 0.999 # Beta 2 for the AdamW optimizer
    weight_decay: 1.0e-6
    eps: 1.0e-8
  lr_scheduler:
    name: "cosine"
    num_warmup_steps: 500
  noise_scheduler:
    num_train_timesteps: 1000
    beta_schedule: "linear" # originally using "squaredcos_cap_v2", changed to linear

# 4. Saving and logging
saving:
  local:
    outputs_dir: 'results/pipelines' # Parent directory for saving outputs
    pipeline_name: 'unconditional_64' # Name of the pipeline
    checkpoint_frequency: 3500 # How often to save checkpoints (in steps)
    saving_frequency: 10 # How often to save the model (in epochs)
  hf:
    repo_name: 'Breast_unconditional_64' # Name of the HF repo
    # model_card_path: 'experiments/model_card.yaml' # Path to model card
logging:
  logger_name: 'tensorboard' # Name of the logger
  dir_name: 'logs' # Name of the logging directory
  images:
    freq_epochs: 10 # How often to save images (in epochs)
    batch_size: 8 # Batch size for image generation